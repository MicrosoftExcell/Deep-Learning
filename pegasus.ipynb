{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pegasus.ipynb","provenance":[{"file_id":"1ylN7K1UlVDvdlC4S2nJpI7rdbK7BAkb5","timestamp":1582049511265},{"file_id":"1oZWtA1Y-g1WcccttesIqKFkR3DeatpyF","timestamp":1581608842491},{"file_id":"1fpAcXYix8B-bQkZ-GZHYVeKT0qEV5IfV","timestamp":1581539278817},{"file_id":"https://gist.github.com/cwkx/f4b49cd3efc0e624bc22c89c90921931#file-spectral-norm-gan-ipynb","timestamp":1581504461569}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"6O3XJulLsD4q","colab_type":"text"},"source":["Code adapted from/uses ideas from:\n","\n","1) C. Willcocks, https://colab.research.google.com/gist/cwkx/f4b49cd3efc0e624bc22c89c90921931/spectral-norm-gan.ipynb (for base of code)\n","\n","2) https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html#sklearn.neighbors.NearestNeighbors.kneighbors (for kNN selection of images)\n","\n","3) U. Desai, https://medium.com/@utk.is.here/keep-calm-and-train-a-gan-pitfalls-and-tips-on-training-generative-adversarial-networks-edd529764aa9 and https://github.com/utkd/gans/blob/master/cifar10dcgan.ipynb (for ideas on adding noise and flipping labels)\n","\n","4) R. Chavhan https://github.com/ruchikachavhan/GANs (for ideas for layers in generator and discriminator)\n","\n","5) J. Brownlee https://machinelearningmastery.com/how-to-train-stable-generative-adversarial-networks/ (for ideas for layers in GAN and layer/optimiser parameters)"]},{"cell_type":"code","metadata":{"id":"X0XeNJMELfIb","colab_type":"code","colab":{}},"source":["%%capture\n","from os.path import exists\n","from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n","accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n","!pip install -q torch torchvision livelossplot"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6N22Uz-kLiZW","colab_type":"text"},"source":["**Main imports**"]},{"cell_type":"code","metadata":{"id":"MK1Jl7nkLnPA","colab_type":"code","colab":{}},"source":["import math\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","from time import sleep\n","from livelossplot import PlotLosses\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","latent_space_size = 100"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oupS1WRTrfwN","colab_type":"code","colab":{}},"source":["imageSize = 64\n","transform2 = transforms.Compose([transforms.Scale(imageSize)]) \n","trainset = torchvision.datasets.CIFAR10('data', train=True, download=True,transform = transform2)\n","print(trainset)\n","testset = torchvision.datasets.CIFAR10('data', train=False, download=True,transform=transform2)\n","print(testset)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LRTJxrcAtM_S","colab_type":"code","colab":{}},"source":["# Normalize the image data. The inputs are 0-255 for each channel.  Convert them to float32\n","# where each value is > -1.9 and <1.0.  Several papers stress the importance of normalizing the input\n","\n","horses = np.empty([6000,3,imageSize,imageSize]).astype(np.float32)\n","birds = np.empty([6000,3,imageSize,imageSize]).astype(np.float32)\n","horsecount = 0;\n","birdcount = 0;\n","for dataset in [trainset, testset]:\n","  for image,label in dataset:\n","    if label == 7:\n","      horses[horsecount] = (np.array(image).swapaxes(0,2).swapaxes(1,2)/128)-0.996\n","      horsecount += 1\n","    if label == 2:\n","      birds[birdcount] = (np.array(image).swapaxes(0,2).swapaxes(1,2)/128)-1.0\n","      birdcount += 1\n","\n","from sklearn.neighbors import NearestNeighbors\n","nbrs = NearestNeighbors(n_neighbors=2000, algorithm='auto').fit(np.reshape(horses, (horses.shape[0], -1)))\n","distances, indices = nbrs.kneighbors(horses[4].reshape(1,-1))\n","\n","new_horses = np.empty([2000,3,imageSize,imageSize]).astype(np.float32)\n","num_horses = 0\n","for i in range(6000):\n","  if i in indices[0]:\n","    for j in range(1):\n","      new_horses[num_horses] = horses[i]\n","      num_horses += 1\n","\n","plt.figure(figsize=(10,10))\n","for i in range(25):\n","  plt.subplot(5,5,i+1)\n","  plt.xticks([])\n","  plt.yticks([])\n","  plt.grid(False)\n","  plt.imshow(((horses[indices[0][i]]/2)+0.5).swapaxes(1,2).swapaxes(0,2), cmap=plt.cm.binary)\n","  plt.xlabel(indices[0][i])\n","\n","nbrs = NearestNeighbors(n_neighbors=1400, algorithm='auto').fit(np.reshape(birds, (birds.shape[0], -1)))\n","distances, indices = nbrs.kneighbors(birds[3387].reshape(1,-1)) #closed wing birds\n","\n","new_birds = np.empty([1400,3,imageSize,imageSize]).astype(np.float32)\n","num_birds = 0\n","for i in range(6000):\n","  if i in indices[0]:\n","    for j in range(1):\n","      new_birds[num_birds] = birds[i]\n","      num_birds += 1\n","\n","nbrs = NearestNeighbors(n_neighbors=400, algorithm='auto').fit(np.reshape(birds, (birds.shape[0], -1)))\n","distances, places = nbrs.kneighbors(birds[626].reshape(1,-1)) #open wing birds\n","\n","open_birds = np.empty([400,3,imageSize,imageSize]).astype(np.float32)\n","num_birds = 0\n","for i in range(6000):\n","  if i in places[0]:\n","    for j in range(1):\n","      open_birds[num_birds] = birds[i]\n","      num_birds += 1\n","\n","plt.figure(figsize=(10,10))\n","for i in range(25):\n","  plt.subplot(5,5,i+1)\n","  plt.xticks([])\n","  plt.yticks([])\n","  plt.grid(False)\n","  plt.imshow(((birds[places[0][i]]/2)+0.5).swapaxes(1,2).swapaxes(0,2), cmap=plt.cm.binary)\n","  plt.xlabel(places[0][i])\n","\n","all_birds = np.concatenate((new_birds,open_birds))\n","pegasus = np.concatenate((new_horses,all_birds))\n","# Use one-hot encoding for classes\n","pegasus_labels = np.concatenate((np.full((2000,3), [0,1,0]), np.full((1800,3), [0,0,1])))\n","\n","# If you want to shuffle the images:\n","# random_idx = np.random.permutation(len(pegasus)) # Create a shuffle index\n","# pegasus = pegasus[random_idx] # Sort both arrays with the same random index\n","# pegasus_labels = pegasus_labels[random_idx]\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UvRHi0SHhARm","colab_type":"code","colab":{}},"source":["from torch.utils.data import Dataset\n","class CustomDataset(Dataset):\n","\n","    def __init__(self, data, labels):\n","        self.data = data\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        return (self.data[idx], self.labels[idx])\n","\n","peg_dataset = CustomDataset(pegasus, pegasus_labels)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KLNHp0IR6XJ_","colab_type":"code","colab":{}},"source":["def cycle(iterable):\n","    while True:\n","        for x in iterable:\n","            yield x\n","\n","horse_iterator = iter(cycle(torch.utils.data.DataLoader(peg_dataset,\n","                                           batch_size=64,\n","                                           shuffle=False)))\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qnjh12UbNFpV","colab_type":"text"},"source":["**Define two models: (1) Generator, and (2) Discriminator**"]},{"cell_type":"code","metadata":{"id":"RGbLY6X-NH4O","colab_type":"code","colab":{}},"source":["# define the model\n","\n","from  torch.nn.modules.upsampling import Upsample\n","\n","# custom weights initialization called on netG and netD\n","def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        nn.init.normal_(m.weight.data, 0.0, 0.02)\n","    elif classname.find('BatchNorm') != -1:\n","        nn.init.normal_(m.weight.data, 1.0, 0.02)\n","        nn.init.constant_(m.bias.data, 0)\n","\n","class Generator(nn.Module): \n","\n","    def __init__(self): \n","        super(Generator, self).__init__() \n","        self.model = nn.Sequential( \n","            nn.ConvTranspose2d(latent_space_size, 512, 4, 1, 0, bias = False), \n","            nn.BatchNorm2d(512), \n","            nn.ReLU(True), \n","            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias = False), \n","            nn.BatchNorm2d(256), \n","            nn.ReLU(True), \n","            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias = False), \n","            nn.BatchNorm2d(128), \n","            nn.ReLU(True), \n","            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias = False), \n","            nn.BatchNorm2d(64), \n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias = False), \n","            nn.Tanh() \n","        )\n","\n","    def generate(self, input): \n","        output = self.model(input) \n","        return output \n","\n","class Discriminator(nn.Module): \n","    def __init__(self): \n","        super(Discriminator, self).__init__() \n","        self.model = nn.Sequential( \n","            torch.nn.utils.spectral_norm(nn.Conv2d(3, 64, 4, 2, 1, bias = False)), \n","            nn.LeakyReLU(0.3, inplace = True), \n","            torch.nn.utils.spectral_norm(nn.Conv2d(64, 128, 4, 2, 1, bias = False)), \n","            nn.BatchNorm2d(128), \n","            nn.LeakyReLU(0.3, inplace = True), \n","            torch.nn.utils.spectral_norm(nn.Conv2d(128, 256, 4, 2, 1, bias = False)), \n","            nn.BatchNorm2d(256), \n","            nn.LeakyReLU(0.3, inplace = True), \n","            torch.nn.utils.spectral_norm(nn.Conv2d(256, 512, 4, 2, 1, bias = False)), \n","            nn.BatchNorm2d(512), \n","            nn.LeakyReLU(0.3, inplace = True), \n","            torch.nn.utils.spectral_norm(nn.Conv2d(512, 3, 4, 1, 0, bias = False)), \n","            nn.Sigmoid() \n","        )\n","\n","    def discriminate(self, input): \n","        output = self.model(input) \n","        return output.view(-1,3) \n","\n","G = Generator().to(device)\n","D = Discriminator().to(device)\n","\n","# Apply the weights_init function to randomly initialize all weights\n","#  to mean=0, stdev=0.2.\n","G.apply(weights_init)\n","D.apply(weights_init)\n","\n","print(f'> Number of generator parameters {len(torch.nn.utils.parameters_to_vector(G.parameters()))}')\n","print(f'> Number of discriminator parameters {len(torch.nn.utils.parameters_to_vector(D.parameters()))}')\n","\n","print(G)\n","\n","lr = 0.0002\n","beta1 = 0.5\n","\n","# initialise the optimiser\n","optimiser_G = torch.optim.Adam(G.parameters(), lr=lr, betas=(beta1, 0.999))\n","optimiser_D = torch.optim.Adam(D.parameters(), lr=lr, betas=(beta1, 0.999))\n","bce_loss = nn.BCELoss()\n","epoch = 0\n","liveplot = PlotLosses()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k3pUat9vK2IJ","colab_type":"code","colab":{}},"source":["x = next(horse_iterator)\n","print(x[0].dtype)\n","print(x[0].size())\n","print(x[0].mean())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N1UBl0PJjY-f","colab_type":"text"},"source":["**Main training loop**"]},{"cell_type":"code","metadata":{"id":"kb5909Y8D_zx","colab_type":"code","colab":{}},"source":["# training loop\n","from torch.autograd import Variable\n","import cv2\n","\n","print(\"start\")\n","epoch = 0\n","\n","\n","def grayscale(data, dtype='float32'):\n","    # luma coding weighted average in video systems\n","    r, g, b = np.asarray(.3, dtype=dtype), np.asarray(.59, dtype=dtype), np.asarray(.11, dtype=dtype)\n","    rst = r * data[:, 0, :, :] + g * data[:, 1, :, :] + b * data[:, 2, :, :]\n","    # add channel dimension\n","    rst = np.expand_dims(rst, axis=1)\n","    return rst\n","\n","while (epoch<100):\n","\n","    # arrays for metrics\n","    logs = {}\n","    gen_loss_arr = np.zeros(0)\n","    dis_loss_arr = np.zeros(0)\n","    enc_loss_arr = np.zeros(0)\n","\n","    # iterate over some of the train dateset\n","    for i in range(60):\n","\n","        # train discriminator \n","        for j in range(2):\n","            x,labels = next(horse_iterator)\n","            x = x.to(device)\n","            optimiser_D.zero_grad()\n","\n","            # The last mini batch may be smaller than batchSize\n","            mini_batch_size = x.size()[0]\n","          \n","            # # target = Variable(torch.ones(mini_batch_size)).to(device)\n","          \n","            # noise_prop = 0.05 # Randomly flip 5% of labels\n","\n","            # # Prepare labels for real data\n","            # true_labels = np.ones((mini_batch_size)) - np.random.uniform(low=0.0, high=0.1, size=(mini_batch_size))\n","            # #flipped_idx = np.random.choice(np.arange(len(true_labels)), size=int(noise_prop*len(true_labels)))\n","            # #true_labels[flipped_idx] = 1 - true_labels[flipped_idx]\n","            # target = Variable(torch.from_numpy(true_labels)).float().to(device)\n","\n","            fake_target = torch.tensor(np.full((mini_batch_size,3), [1, 0, 0])).float().to(device)\n","\n","            g = G.generate(torch.randn(x.size(0), latent_space_size, 1, 1).to(device))\n","            l_r = bce_loss(D.discriminate(x), labels.float().to(device)) # real -> 1\n","            l_f = bce_loss(D.discriminate(g.detach()), fake_target) #  fake -> 0\n","            loss_d = (l_r + l_f)\n","            loss_d.backward()\n","            optimiser_D.step()\n","          \n","        # train generator\n","        x,labels = next(horse_iterator)\n","        x = x.to(device)\n","        optimiser_G.zero_grad()\n","        g = G.generate(torch.randn(x.size(0), latent_space_size, 1, 1).to(device))\n","\n","        loss_g = bce_loss(D.discriminate(g),torch.tensor(np.full((x.size()[0],3), [0.05,0.6,0.4])).float().to(device) ) # fake -> 1\n","        loss_g.backward()\n","        optimiser_G.step()\n","\n","        gen_loss_arr = np.append(gen_loss_arr, loss_g.item())\n","        dis_loss_arr = np.append(dis_loss_arr, loss_d.item())\n","\n","    # plot some examples\n","    imgs = np.array(g.cpu().detach())\n","\n","    print(\"Epoch: %d\" % epoch)\n","    plt.figure(figsize=(10,10))\n","    for i in range(10):\n","        k = (imgs[i]/2)+0.5\n","       # smooth = cv2.GaussianBlur(k,(5,5),0)\n","       # img = k + 0.5*(k-smooth)\n","        gaussian = cv2.GaussianBlur(k, (7,7), 6.0)\n","        unsharp_image = cv2.addWeighted(k, 1.5, gaussian, -0.5, 0)\n","        img = cv2.normalize(unsharp_image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n","        plt.subplot(5,5,i+1)\n","        plt.xticks([])\n","        plt.yticks([])\n","        plt.grid(False)\n","        plt.imshow(img.swapaxes(1,2).swapaxes(0,2), cmap=plt.cm.binary)\n","        plt.xlabel(\"Generated % d\" % i)\n","    plt.show()\n","\n","    epoch = epoch+1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-KK4IR3dHuLA","colab_type":"code","colab":{}},"source":["# Get the horsiness and birdiness of images\n","# def test_classifier(desc, dataset):\n","#   set_loader = iter(torch.utils.data.DataLoader(dataset,batch_size=16,shuffle=False))\n","#   batch = next(set_loader)\n","#   classes = D.discriminate(batch.to(device))\n","#   print('Classification of %s images:' % desc)\n","#   for real, horse, bird in classes:\n","#     print(\"%.4f %.4f %.4f\" % (real, horse, bird))\n","\n","# test_classifier(\"horse\", horses)\n","# test_classifier(\"bird\", birds)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pu9e292SH1oq","colab_type":"code","colab":{}},"source":["def sortby(x):\n","    return x[:,1]+x[:,2] # Sort by horsiness + birdiness\n","\n","def best_pegasus():\n","  gen_images = G.generate(torch.randn(64, latent_space_size, 1, 1).to(device))\n","  classes = D.discriminate(gen_images).cpu().detach().numpy()\n","  ordered = np.argsort(sortby(classes))\n","  best = gen_images[ordered]\n","  classes = np.flip(classes[ordered], axis=0)\n","  return((best[0], classes[0]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"j2HC2YezH86k","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(20,20))\n","for i in range(64):\n","    plt.subplot(8,8,i+1)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.grid(False)\n","    best_img, classes = best_pegasus()\n","    img = best_img.cpu().detach().numpy().swapaxes(0,2).swapaxes(0,1)\n","    gaussian = cv2.GaussianBlur(img, (7,7), 6.0)\n","    unsharp_image = cv2.addWeighted(img, 1.5, gaussian, -0.5, 0)\n","    final_img = cv2.normalize(unsharp_image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n","    plt.imshow(final_img, interpolation = 'bicubic')\n","    #plt.xlabel('%.3f %.5f %.5f' % (classes[0], classes[1], classes[2]))\n","    plt.xlabel(i)"],"execution_count":0,"outputs":[]}]}